---
title: "Modélisation bayésienne pour l'écologie"
output: 
  html_document:
   toc: true
   toc_float: true
   logo: LogoAgrocampusOuest.jpg
   number_sections: false
   highlight: tango
   css: style.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
library(tibble)
library(tidyr)
library(stringr)
library(purrr)
library(ggplot2)
library(dplyr)
library(knitr)
```


Les slides sont disponibles  
[Cours Partie1](bayes_cours_1.pdf)
[Cours Partie2](bayes_cours_2.pdf)

# Installation logiciel

Pour les manipulations, nous aurons besoin de 
OpenBugs disponible [ici](http://www.openbugs.net/w/FrontPage).

Sous linux, il faut installer [wine](https://www.winehq.org/) puis OpenBugs sous wine.

On va utliser également [Jags](http://mcmc-jags.sourceforge.net/) disponible sous Linux et Windows et le package [rjags](http://cran.r-project.org/package=rjags).


# Rappel sur quelques lois de probabilités utiles dans un cadre bayésien
Un petit rappel sur les lois de probabilité utiles pour la modélisation bayésienne est disponible sur la page [Rappel](rappel_loi.html)



# Application using the binomial model for capture data


While monitoring a large population of size $n$ unknown, $m$ individuals have been marked and released.
The population might be considered as $m$ marked individuals and $n-m$ unmarked individuals. 
A recapture experiment leads to $YM$ marked animals and $YNM$ unmarked. What is the size of the population.


## Modelling and Estimating the capture efficiency

The probability of capture might be infered from the recapture dataset and the experiment might be modelled as 
\begin{equation}
 YM \sim \mathcal{B}(m, p).
\end{equation}

The capture mark recapture experiment has been used for the first time on these conditions. Few is known on the probability of capture. Therefore an uniform prior is chosen to model the a priori knowledge on $p$.

### Data
```{r}
m <- 53
YM <- 9
```

### Theoretical posterior distribution
Because the uniform distribution is a special case of beta distribution, the full bayesian specification for the model is a so called beta binomial model which has analytical posterior distribution.

$$\pi(p\vert  YM_{obs}) \sim \mathcal{B}eta(YM + 1,  m-YM +1)$$

```{r}
s1 <- 1
s2 <- 1
p <- ggplot(data = data.frame(x=seq(0,1, length.out = 100)))
stat_post <- stat_function(aes(x = x, y = ..y..), fun = dbeta, colour="red", n = 100,
                      args = list(shape1 = YM+s1, shape2 = m-YM+s2))
stat_prior <- stat_function(aes(x = x, y = ..y..), fun = dbeta, colour="green", n = 100,
                      args = list(shape1 = s1, shape2 = s2))
p + stat_prior +stat_post

```


## Implementing a MCMC algorithm

### Compute the likelihood for a given value of $p$

```{r}
binom_loglikelihood<- function(y, p, m){
  dbinom(x = y, size=m, prob = p)
}

binom_loglikelihood(y=YM, p=0.1, m=m)
binom_loglikelihood(y=YM, p=0.2, m=m)

```

### A function to update the current parameter value

```{r}
rprop <- function(p.courant, sd.explore=0.1){
  p.courant + sd.explore*rnorm(1)
}

dprop <- function(p.courant, p.propose, sd.explore=0.1){
 dnorm(p.courant-p.propose, sd=sd.explore)
}

```

### Metropolis Hastings ratio

```{r}
ratio <- function(p.courant, p.propose, sd.explore){
  if(p.propose>1 || p.propose <0 ){
    rat <- 0
  } else
  {
   rat <-  (binom_loglikelihood(YM, p.propose, m=m) * dbeta(p.propose, s1, s2)) / (binom_loglikelihood(YM, p.courant, m=m) * dbeta(p.courant, s1, s2))*(dprop(p.propose, p.courant, sd.explore) / dprop(p.courant, p.propose, sd.explore)) 
  }
  return(rat)
}
```

### Metropolis Hastings algorithm

```{r}
p.init     <- 0.8
n.iter     <- 500
sd.tune    <- 0.1

p.post     <- rep(NA, n.iter)
p.courant  <- p.init
  
for (i in 1 : n.iter){
   p.cand <- rprop(p.courant, sd.explore = sd.tune)  
   rat <- ratio(p.courant, p.cand, sd.tune)
   if(runif(1)<rat){
     p.post[i] <-  p.courant <- p.cand
   } else {
     p.post[i] <- p.courant
   }
}

df.post  <- data.frame(p.post=p.post, niter=1:n.iter)
p <- ggplot(data = df.post, aes(x=niter, y=p.post)) + geom_point()
p

p <- ggplot(data = df.post, aes(x=p.post)) + geom_histogram(aes(y=..density..)) + xlim(c(0,1)) +stat_function(aes(x = p.post, y = ..y..), fun = dbeta, colour="green", n = 100,
                      args = list(shape1 = s1, shape2 = s2)) + stat_function(aes(x = p.post, y = ..y..), fun = dbeta, colour="red", n = 100,
                      args = list(shape1 = YM+s1, shape2 = m-YM+s2))
p

```





# Captures successives sans remise

## Problématique et modélisation

La méthode d'inventaire de DeLury (DeLury,1947) consiste à effectuer
un certain nombre de pêches successives pour évaluer la taille d'une
population inconnue $\nu$ à l'aide d'un dispositif de capture (le plus
souvent pêche électrique) d'efficacité $\pi$ . L'efficacité
$\pi$ est la probabilité de capture d'un individu: elle dépend du
milieu et de l'effort de pêche, et peut dépendre de la taille de
l'individu. Les poissons capturés à chaque pêche ne sont ni
marqués, ni remis à l'eau. 

On appelle $m$ ce nombre de pêches successives et $C_{1}, C_{2}, \ldots, C_{i},\ldots,C_{m}$ les quantités capturées successivement obtenues.

* A l'aide de la loi binomiale, proposer un modèle simple d'échantillonnage de $C_{1},C_{2},\ldots,C_{i},\ldots,C_{m}$ et en dessiner le
	graphe acyclique orienté (DAG).
* Exprimer les hypothèses qui sous-tendent votre modélisation.
* Dire quelles sont les observables et quels sont les paramètres.
* Ecrire un programme de simulation sous $R$ \ qui simule un enlèvement de $m=4$ pêches d'une population de poissons.

On pourra prendre $\nu=50$ et $\pi=\frac{1}{4}$ pour fixer les idées.

<!-- \subsection{Considérations fréquentistes} -->

<!-- Pour évaluer le peuplement le plus probable (dans un contexte -->
<!-- fréquentiste) la classique méthode d'estimation de DeLury consiste -->
<!-- à tracer la droite de régression sur les points $(x_{i},y_{i}% -->
<!-- )_{i=1:n}$ avec $(x_{1}=0,y_{1}=C_{1})$ et pour $i>1:$ -->
<!-- \begin{align*} -->
<!-- x_{i}  & =\sum_{j=1}^{i-1}C_{j}\\ -->
<!-- y_{i}  & =C_{i}% -->
<!-- \end{align*} -->


<!-- L'estimation classique du peuplement est donnée par l'abscisse de -->
<!-- l'intersection de cette droite et de l'axe des $x.$ -->

<!-- \begin{itemize} -->
<!-- 	\item Donner l'idée constructive (pourquoi un modèle linéaire?) -->
<!-- 	qui sous-tend la manière d'obtenir cet estimateur $\hat{\nu}(C_{1}% -->
<!-- 	,C_{2},...C_{i},...C_{m})$ et montrer comment la pente de cette droite est -->
<!-- 	alors utile pour proposer une estimation $\hat{\pi}$ de $\pi.$ -->

<!-- 	\item En déduire quelles sont les limites de cette estimation fréquentiste. -->

<!-- 	\item En repétant un grand nombre de fois  votre programme de simulation -->
<!-- 	sous $R$ \ (qui simule un enlèvement de $m=3\ $pêches d'une population -->
<!-- 	de poissons) et en ne conservant que les jeux de données o\`{u} la -->
<!-- 	technique d'estimation de DeLury "marche", évaluer le biais et la variance -->
<!-- 	des estimateurs de la population et de l'efficacité du dispositif (On -->
<!-- 	rappelle que, sous $R,$ la procédure $lm(y\sim x)$ permet d'obtenir, sous -->
<!-- 	forme d'une liste, les divers résultats de la régression linéaire -->
<!-- 	du vecteur $y$ sur le vecteur $x$). Donner néanmoins également le taux de bon -->
<!-- 	fonctionnement de cette procédure. (On pourra conserver $\nu=50$ et -->
<!-- 	$\pi=\frac{1}{4}$ pour fixer les idées au commencement de cet exercice, -->
<!-- 	mais faire varier $m$ au moins de $2$ à $4$ pour voir comment le nombre de -->
<!-- 	pêches joue sur la qualité de cette procédure d'estimation classique). N'oubliez pas de faire un ou des dessins illustratifs! -->

<!-- 	\item Si le temps dont vous disposez le permet, considérer 9 cas: $\nu$ -->
<!-- 	petit, moyen, grand et  $\pi$ petit, moyen ou grand, pour discuter des -->
<!-- 	qualités de la méthode de DeLury.  -->
<!-- 	\item Obtient-on les même estimateurs si on inverse les rôles de $x$ et $y$ dans le calcul? Etudier par simulation les propriétés de ces estimations alternatives? -->
<!-- \end{itemize} -->

## Estimation par méthode bayésienne

Montrer qu'une loi béta de paramètres $a=1,$ $b=3$ est une loi a
priori très acceptable pour encoder le jugement d'un expert en dispositif
de pêche électrique annonçant que sa meilleure évaluation
personnelle pour $\pi$ est de l'ordre de $\frac{1}{4}$ $\ $\ et qu'il est
prêt à parier  $50\%/50\%$ environ sur l'intervalle $[0.1,0.4].$

* Simuler les résultats un enlèvement de $m=4\ $pêches d'une	population de poissons avec $\nu=50$ et $\pi=\frac{1}{4}$ pour créer un
	jeu de données.
* Ecrire un programme avec appel à WinBUGS (ou jags) pour réaliser
	l'inférence du modèle après avoir choisi un prior peu informatif
	pour  $\nu$.
* Le faire tourner sur données simulées et vérifier la bonne
	qualité de l'encadrement réalisé par la loi a posteriori des
	"inconnues". 
* On pourra choisir quelques valeurs types du triplet génératif ($m,\nu,\pi$) pour illustrer sur des jeux de données différents le fonctionnement de cette inférence bayésienne.
* Appliquer votre méthode bayésienne sur les deux jeux de
	données d'anguilles et vairons du Couesnon, (données tirées d'une
	enquête de Beaudouin et Pontini (1973) et reprises dans le tableau
	suivant), discuter des résultats (en imaginant que vous ayez acces aux données en deux temps : d'abord seulement les deux premières pêches, puis ensuite les trois pêches) et traduire les résultats de cette
	approche en recommandations à l'intention des gestionnaires du cours d'eau:

```{r, echo = FALSE}
df <- data.frame(Espèces = c('Anguilles', 'Vairons'), Peche1 = c(28, 60), Peche2=c(11,54), Peche3=c(4,58))
kable(df, caption = 'Données extraites de Beaudouin et Pontini (1973)' )
```



## Bibliographie
* Beaudouin P., Pontini G., 1973. étude hydrobiologique du bassin du
	Couesnon. Diplôme d'Agronomie approfondie, E. N . S. A., Rennes.
* DeLury D.B.,1947. On the estimation of biological populations. Biometrics,
	3(4) , 145-167.



# TD estimation de la taille d'une poulation d'otaries

L'objectif du TD est d'estimer al aille d'une population d'otaries sur l'ile Marion en Antarctique.

Un extrait de la publication présentant les données et le problème est disponible  [ici](data/Data-TDPup/Wege_et_al-2016-Marine_Mammal_Science.pdf).

Nous nous appuierons sur 3 jeux de données qui sont
* les expériences de capture marquage recapture [CMR_Data](data/Data-TDPup/CMR_Davis.csv)
* les comptages directs [DC_Data](data/Data-TDPup/CDDirectCount_Davis.csv)
* Les comptages depuis la falaise [Cliff_data](ClifftopCounts_Davis.csv)


